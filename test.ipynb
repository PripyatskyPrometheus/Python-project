{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import loadtxt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "from tqdm import trange\n",
    "from pymystem3 import Mystem\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выгружаем исходный набор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class_mark</th>\n",
       "      <th>text_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>Оно\\nМои фильмы из помойки!Мам, а у нас еще ос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bad</td>\n",
       "      <td>Оно\\nМои фильмы из помойки!Сразу скажу, что я ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bad</td>\n",
       "      <td>Оно\\nМои фильмы из помойки!Если сравнивать ста...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bad</td>\n",
       "      <td>Оно\\nМои фильмы из помойки!— Прошу меня извини...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bad</td>\n",
       "      <td>Оно\\nМои фильмы из помойки!Для начала, опишу х...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 class_mark                                        text_review\n",
       "0           0        bad  Оно\\nМои фильмы из помойки!Мам, а у нас еще ос...\n",
       "1           1        bad  Оно\\nМои фильмы из помойки!Сразу скажу, что я ...\n",
       "2           2        bad  Оно\\nМои фильмы из помойки!Если сравнивать ста...\n",
       "3           3        bad  Оно\\nМои фильмы из помойки!— Прошу меня извини...\n",
       "4           4        bad  Оно\\nМои фильмы из помойки!Для начала, опишу х..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datafraem.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class_mark</th>\n",
       "      <th>text_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Оно\\nМои фильмы из помойки!Мам, а у нас еще ос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Оно\\nМои фильмы из помойки!Сразу скажу, что я ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Оно\\nМои фильмы из помойки!Если сравнивать ста...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Оно\\nМои фильмы из помойки!— Прошу меня извини...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Оно\\nМои фильмы из помойки!Для начала, опишу х...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  class_mark                                        text_review\n",
       "0           0           0  Оно\\nМои фильмы из помойки!Мам, а у нас еще ос...\n",
       "1           1           0  Оно\\nМои фильмы из помойки!Сразу скажу, что я ...\n",
       "2           2           0  Оно\\nМои фильмы из помойки!Если сравнивать ста...\n",
       "3           3           0  Оно\\nМои фильмы из помойки!— Прошу меня извини...\n",
       "4           4           0  Оно\\nМои фильмы из помойки!Для начала, опишу х..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "change_labels = lambda x: 0 if x=='bad' else 1\n",
    "data['class_mark'] = data['class_mark'].apply(change_labels)\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем текстики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lemmatize(arr: list):\n",
    " \n",
    "    text_nomalization = ' '.join(arr).lower() \n",
    "\n",
    "    m = Mystem()\n",
    "    lemmas = m.lemmatize(text_nomalization)\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_non_alphabets = lambda x: re.sub(r'[^а-яА-Я]',' ',str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda x: word_tokenize(x, language = \"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "stem = lambda w: [ ps.stem(x) for x in w ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_review'] = data['text_review'].apply(remove_non_alphabets)\n",
    "data['text_review'] = data['text_review'].apply(tokenize)\n",
    "data['text_review'] = data['text_review'].apply(stem)\n",
    "\n",
    "c = 0\n",
    "for i in data.index:\n",
    "    data['text_review'][i] = Lemmatize(data['text_review'][i])\n",
    "    data[\"text_review\"][i] = [elem for elem in data[\"text_review\"][i] if elem!=' ']\n",
    "    c+=1\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производим разделение загруженного набора данных на обучающую, тестовую и валидационую выборки (в соотношении 80:10:10). Проверяем, что сформированные выборки сбалансированы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_seed = random.randint(0,10)\n",
    "train_df = data.sample(frac=0.9, random_state=frac_seed, ignore_index=True)\n",
    "valid_df = data.sample(frac=0.1, random_state=frac_seed, ignore_index=True)\n",
    "for i in valid_df[\"text_review\"]:\n",
    "    while i in train_df['text_review']: \n",
    "        tmp = data.sample()\n",
    "        i[\"text_review\"] = tmp['text_review']\n",
    "        i[\"class_mark\"] = tmp[\"class_mark\"]\n",
    "     \n",
    "train_df.to_csv(\"train_df.csv\")\n",
    "valid_df.to_csv(\"valid_df.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём модель нейронной сети для решения задачи классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "stopWords = stopwords.words('russian')\n",
    "\n",
    "cv = CountVectorizer(max_features=max_words , stop_words=stopWords)\n",
    "\n",
    "sparse_matrix = cv.fit_transform(train_df[\"text_review\"]).toarray()\n",
    "valid_sparse_matrix = cv.fit_transform(valid_df[\"text_review\"]).toarray()\n",
    "print(sparse_matrix.shape)\n",
    "print(valid_sparse_matrix.shape)\n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(valid_sparse_matrix, np.array(valid_df[\"class_mark\"]))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(sparse_matrix, np.array(train_df[\"class_mark\"]),test_size = 0.12, train_size= 0.88)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описаываем пайплайн предобработки данных. ВАЖНО: что так как ваш вариант предполагает работу с текстом, то необходимо выполниить векторизацию данных (подробности в туториале)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear1 = nn.Linear(10000, 100)\n",
    "        self.linear2 = nn.Linear(100, 10)\n",
    "        self.linear3 = nn.Linear(10, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "x_train = Variable(torch.from_numpy(x_train)).float()\n",
    "y_train = Variable(torch.from_numpy(y_train)).long()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать train loop (цикл обучения). Провести эксперименты по обучению с различными значениями параметров learning rate (скорость обучения) и batch size (размер мини-пакета). Выбрать по 3 значения для learning rate и batch size (итоговое количество экспериментов будет 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expirement(lr, batch_size):\n",
    "    model = LogisticRegression()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    data = torch.utils.data.DataLoader(x_train, batch_size = batch_size)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters() , lr = lr)\n",
    "    epochs = 10\n",
    "    model.train()\n",
    "    loss_values = []\n",
    "    acc_values = list()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for elems in data: \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_pred = model(x_train)\n",
    "            \n",
    "            \n",
    "            loss = criterion(y_pred, y_train)\n",
    "            loss_values.append(loss.item())\n",
    "            pred = torch.max(y_pred, 1)[1].eq(y_train).sum()\n",
    "            acc = pred * 100.0 / len(x_train)\n",
    "            acc_values.append(acc)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    epochs_values = list()\n",
    "    for i in range(0,epochs): epochs_values.append(i)\n",
    "    \n",
    "    loss_values_graph = list()\n",
    "    \n",
    "    for i in range(0,len(loss_values), len(loss_values)//epochs):\n",
    "        loss_values_graph.append(loss_values[i])\n",
    "        \n",
    "    acc_values_graph = list()\n",
    "    \n",
    "    for i in range(0,len(acc_values), len(acc_values)//epochs):\n",
    "        acc_values_graph.append(acc_values[i])\n",
    "    \n",
    "    plt.plot(epochs_values, loss_values_graph)\n",
    "    plt.title('Loss Value vs Epochs by lr='+str(lr) +' batch_size='+str(batch_size))\n",
    "    plt.xlabel('Epochs',)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Loss'])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(epochs_values, acc_values_graph, color = 'g')\n",
    "    plt.title('Таблица эпох и качества при lr='+str(lr) + 'batch_size='+str(batch_size))\n",
    "    plt.xlabel('Эпоха',)\n",
    "    plt.ylabel('Точность')\n",
    "    plt.legend(['Точность'])\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого проведенного эксперимента выводим графики для значения функции потерь (ось x - итерация обучения/номер эпохи; ось y - значение функции потерь) и выбранной метрики качества (ось x - итерация обучения/номер эпохи; ось y - значение метрики качества). Графики необходимо выводить как для обучающей, так и для валидационной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_models = list()\n",
    "lr_list=[0.0001,0.0002,0.0003]\n",
    "batch_size=[1000,500,100]\n",
    "\n",
    "for LR in lr_list:\n",
    "        for BZ in batch_size:\n",
    "            my_models.append(expirement(LR,BZ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем качество работы модели на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "lr_number = 0\n",
    "bs_number = 0\n",
    "acc_list = list()\n",
    "for model in my_models:  \n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    x_test = torch.Tensor(x_test).float()\n",
    "    y_test=[int(i) for i in y_test]\n",
    "    y_test = torch.Tensor(y_test).long()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(100):\n",
    "            y_pred = model(x_test)\n",
    "            loss = criterion(y_pred, y_test)\n",
    "            pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n",
    "        acc = 100*pred/len(x_test)\n",
    "        acc_list.append(acc)\n",
    "        print ( 'Number of model = ', j,'LR: ', lr_list[lr_number],'BS: ',batch_size[bs_number] ,' ----> Accuracy : {}%'.format(100*pred/len(x_test)))\n",
    "        bs_number += 1\n",
    "        if j%3 == 0: \n",
    "            lr_number += 1\n",
    "            bs_number = 0\n",
    "        j +=1\n",
    "print(\"Max acc: \", float(max(acc_list))  )   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем выводы по полученным результатам проведенных экспериментов. Какую модель из всех полученных стоит использовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранияем обученную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for model in my_models:\n",
    "    torch.save(model.state_dict(), os.path.join('./', f'model{i}.pt'))\n",
    "    i+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполняем повторную инициализацию модели и загрузку весов(где-то там, в мыслях:)). Демонстрируем работоспособность модели(снова там же:)) (пропустите через нее какой-то отзыв/рецензию и выведите результат)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0d7deea41377acd7594bbedbdb6d7223a9e220dd91b2cbf4252681cb7a443c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
